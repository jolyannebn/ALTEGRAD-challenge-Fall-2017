{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# General\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# For split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Features extraction\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "# Grid search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Scores\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss\n",
    "from fuzzywuzzy import fuzz\n",
    "from jellyfish import jaro_distance, jaro_winkler\n",
    "\n",
    "# Figure and plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "import re \n",
    "import itertools\n",
    "import operator\n",
    "import copy\n",
    "import igraph\n",
    "import heapq\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from igraph import plot\n",
    "from library import clean_text_simple, terms_to_graph, unweighted_k_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stpwds = stopwords.words('english')\n",
    "punct = string.punctuation.replace('-', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_pos_tag_sentence(d):\n",
    "    sent = tuple(d.split())\n",
    "    return nltk.pos_tag(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_pos_tag_word(d):  \n",
    "    return nltk.pos_tag(nltk.word_tokenize(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_pos_tag_word_single_words(word):  \n",
    "    buf = nltk.pos_tag(nltk.word_tokenize(word))\n",
    "    print(buf, buf[0], buf[1])\n",
    "    return nltk.pos_tag(nltk.word_tokenize(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getPosTagDescription(pos):\n",
    "    return posTagDescription[pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def transform_sentence_to_pos_tag(d):\n",
    "    pos = get_pos_tag_sentence(d)\n",
    "    lst = \"\"\n",
    "    sep = \"\"\n",
    "    for p in pos:\n",
    "        lst = lst + sep + p[1]\n",
    "        sep = \" \"\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "posTagDescription = {\n",
    "    'CC': 'coordinating conjunction or',\n",
    "    'CD': 'cardinal number 2, second',\n",
    "    'DT': 'determiner the',\n",
    "    'EX': 'existential there there are',\n",
    "    'FW': 'foreign word kindergarten',\n",
    "    'IN': 'preposition/subordinating conjunction on, of, like',\n",
    "    'JJ': 'adjective cool',\n",
    "    'JJR': 'adjective, comparative cooler',\n",
    "    'JJS': 'adjective, superlative coolest',\n",
    "    'LS': 'list marker 1)',\n",
    "    'MD': 'modal could, will',\n",
    "    'NN': 'noun, singular or mass book',\n",
    "    'NNS': 'noun plural books',\n",
    "    'NNP': 'proper noun, singular Sean',\n",
    "    'NNPS': 'proper noun, plural Vikings',\n",
    "    'PDT': 'predeterminer both the boys',\n",
    "    'POS': 'possessive ending friend\\'s',\n",
    "    'PRP': 'personal pronoun I, he, it',\n",
    "    'PRP$': 'possessive pronoun my, his',\n",
    "    'RB': 'adverb however, usually, naturally, here, good',\n",
    "    'RBR': 'adverb, comparative better',\n",
    "    'RBS': 'adverb, superlative best',\n",
    "    'RP': 'particle give up',\n",
    "    'TO': 'to to go, to him',\n",
    "    'UH': 'interjection uhhuhhuhh',\n",
    "    'VB': 'verb, base form take',\n",
    "    'VBD': 'verb, past tense took',\n",
    "    'VBG': 'verb, gerund/present participle taking',\n",
    "    'VBN': 'verb, past participle taken',\n",
    "    'VBP': 'verb, sing. present, non-3d take',\n",
    "    'VBZ': 'verb, 3rd person sing. present takes',\n",
    "    'WDT': 'wh-determiner which',\n",
    "    'WP': 'wh-pronoun who, what',\n",
    "    'WP$': 'possessive wh-pronoun whose',\n",
    "    'WRB': 'wh-abverb where, when'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def display_info_graph(s1):\n",
    "    # pre-process document\n",
    "    t1 = clean_text_simple(s1, my_stopwords=stpwds, punct=punct, remove_stopwords=False, pos_filtering=False, stemming=False)\n",
    "    g = terms_to_graph(t1, w=3)\n",
    "\n",
    "    # number of edges\n",
    "    print \"\\nnumber of edges:\\n\", len(g.es)\n",
    "\n",
    "    # the number of nodes should be equal to the number of unique terms\n",
    "    len(g.vs) == len(set(t1))\n",
    "\n",
    "    edge_weights = []\n",
    "    for edge in g.es:\n",
    "        source = g.vs[edge.source]['name']\n",
    "        target = g.vs[edge.target]['name']\n",
    "        weight = edge['weight']\n",
    "        edge_weights.append([source, target, weight])\n",
    "\n",
    "    print \"\\nedge_weights:\\n\", edge_weights\n",
    "\n",
    "    \"\"\"for w in range(2,11):\n",
    "        g = terms_to_graph(my_tokens, w)\n",
    "        print g.density()\"\"\"\n",
    "\n",
    "    # decompose g\n",
    "    core_numbers = unweighted_k_core(g)\n",
    "    print \"\\ncore_numbers:\\n\", core_numbers\n",
    "\n",
    "    # compare with igraph method\n",
    "    print \"\\ncompare with igraph method:\\n\", dict(zip(g.vs[\"name\"],g.coreness()))\n",
    "\n",
    "    # retain main core as keywords\n",
    "    max_c_n = max(core_numbers.values())\n",
    "    keywords = [kwd for kwd, c_n in core_numbers.iteritems() if c_n == max_c_n]\n",
    "    print \"\\nkeywords:\\n\", keywords\n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_keywords(s1):\n",
    "    t1 = clean_text_simple(s1, my_stopwords=stpwds, punct=punct, remove_stopwords=False, pos_filtering=False, stemming=False)\n",
    "    g = terms_to_graph(t1, w=2)\n",
    "\n",
    "    edge_weights = []\n",
    "    for edge in g.es:\n",
    "        source = g.vs[edge.source]['name']\n",
    "        target = g.vs[edge.target]['name']\n",
    "        weight = edge['weight']\n",
    "        edge_weights.append([source, target, weight])\n",
    "\n",
    "    core_numbers = unweighted_k_core(g)\n",
    "  \n",
    "    max_c_n = max(core_numbers.values())\n",
    "    keywords = [kwd for kwd, c_n in core_numbers.iteritems() if c_n == max_c_n]\n",
    "    \n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train.csv', names=['row_ID', 'text_a_ID', 'text_b_ID', 'text_a_text', 'text_b_text', 'target'])\n",
    "train, test = train_test_split(df, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_ID</th>\n",
       "      <th>text_a_ID</th>\n",
       "      <th>text_b_ID</th>\n",
       "      <th>text_a_text</th>\n",
       "      <th>text_b_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>422283</td>\n",
       "      <td>387926</td>\n",
       "      <td>What does surgical strike mean?</td>\n",
       "      <td>What is the surgical strike?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>78910</td>\n",
       "      <td>83625</td>\n",
       "      <td>What is the best method of losing weight?</td>\n",
       "      <td>How should I loose weight?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>192860</td>\n",
       "      <td>103497</td>\n",
       "      <td>What is the best way to spank someone?</td>\n",
       "      <td>What is the best way to spank myself?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>353154</td>\n",
       "      <td>165955</td>\n",
       "      <td>Is it safe to apply aloe vera gel on the face ...</td>\n",
       "      <td>How can I buy the best aloe vera gel for face?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>232757</td>\n",
       "      <td>329622</td>\n",
       "      <td>What is the craziest question ever asked on Qu...</td>\n",
       "      <td>What are some of the weirdest questions asked ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    row_ID  text_a_ID  text_b_ID  \\\n",
       "11      11     422283     387926   \n",
       "43      43      78910      83625   \n",
       "15      15     192860     103497   \n",
       "12      12     353154     165955   \n",
       "36      36     232757     329622   \n",
       "\n",
       "                                          text_a_text  \\\n",
       "11                    What does surgical strike mean?   \n",
       "43          What is the best method of losing weight?   \n",
       "15             What is the best way to spank someone?   \n",
       "12  Is it safe to apply aloe vera gel on the face ...   \n",
       "36  What is the craziest question ever asked on Qu...   \n",
       "\n",
       "                                          text_b_text  target  \n",
       "11                       What is the surgical strike?       1  \n",
       "43                         How should I loose weight?       1  \n",
       "15              What is the best way to spank myself?       0  \n",
       "12     How can I buy the best aloe vera gel for face?       0  \n",
       "36  What are some of the weirdest questions asked ...       1  "
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def transformKeywordsIntoType(sent):\n",
    "    lst, sep = \"\", \"\"\n",
    "    for idx, word in enumerate(sent):\n",
    "        buf = nltk.pos_tag(nltk.word_tokenize(word))\n",
    "        lst = lst + sep + buf[0][1]\n",
    "        sep = \" \"\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "texts = {}\n",
    "pairs_train = []\n",
    "pairs_test = []\n",
    "y_train = []\n",
    "y_true = []\n",
    "\n",
    "for idx, l in enumerate(train.values):\n",
    "    \n",
    "    if l[1] not in texts:\n",
    "        texts[l[1]] = transformKeywordsIntoType(get_keywords(l[3]))\n",
    "    if l[2] not in texts:\n",
    "        texts[l[2]] = transformKeywordsIntoType(get_keywords(l[4]))\n",
    "\n",
    "    pairs_train.append([l[1], l[2]])\n",
    "\n",
    "    y_train.append(int(l[5]))\n",
    "    \n",
    "for idx, l in enumerate(test.values):\n",
    "    if l[1] not in texts:\n",
    "        texts[l[1]] = transformKeywordsIntoType(get_keywords(l[3]))\n",
    "    if l[2] not in texts:\n",
    "        texts[l[2]] = transformKeywordsIntoType(get_keywords(l[4]))\n",
    "\n",
    "    pairs_test.append([l[1], l[2]])\n",
    "\n",
    "    y_true.append(int(l[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ids2ind = {} # will contain the row idx of each unique text in the TFIDF matrix \n",
    "for qid in texts:\n",
    "    ids2ind[qid] = len(ids2ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer()\n",
    "A = vec.fit_transform(texts.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def common_words(q1, q2):\n",
    "    everseen = list()\n",
    "    common = 0\n",
    "    for i, tag in enumerate(q1):\n",
    "        if tag in q2:\n",
    "            everseen.append(tag)\n",
    "            common = common + 1\n",
    "        else :\n",
    "            everseen.append(tag)\n",
    "    return common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def diff_words(q1, q2):\n",
    "    everseen = list()\n",
    "    diff = 0\n",
    "    for tag in q1:\n",
    "        if tag not in q2:\n",
    "            everseen.append(tag)\n",
    "            diff = diff + 1\n",
    "        else :\n",
    "            everseen.append(tag)          \n",
    "    for tag in q2:\n",
    "        if tag not in (everseen and q2):\n",
    "            everseen.append(tag)\n",
    "            diff = diff + 1\n",
    "    return diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def fuzzy(q1_text, q2_text):   \n",
    "    q1_tokens=q1_text.split()\n",
    "    q2_tokens=q2_text.split()\n",
    "    fuzzy_distances = np.array([\n",
    "        fuzz.ratio(q1_tokens, q2_tokens),\n",
    "        fuzz.partial_ratio(q1_tokens, q2_tokens),\n",
    "        fuzz.token_sort_ratio(q1_tokens, q2_tokens),\n",
    "        fuzz.token_set_ratio(q1_tokens, q2_tokens),\n",
    "        fuzz.partial_token_sort_ratio(q1_tokens, q2_tokens),\n",
    "    ], dtype='float')\n",
    "    \n",
    "    # Normalize to [0 - 1] range.\n",
    "    fuzzy_distances /= 100\n",
    "    \n",
    "    jelly_distances = np.array([\n",
    "        jaro_distance(q1_text, q2_text),\n",
    "        jaro_winkler(q1_text, q2_text),\n",
    "    ])\n",
    "    \n",
    "    return np.concatenate([fuzzy_distances, jelly_distances])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NB_FEATURES = 1\n",
    "N_train = len(pairs_train)\n",
    "X_train = np.zeros((N_train, NB_FEATURES))\n",
    "N_test = len(pairs_test)\n",
    "X_test = np.zeros((N_test, NB_FEATURES))\n",
    "\n",
    "for i in range(len(pairs_train)):\n",
    "    q1 = pairs_train[i][0]\n",
    "    q2 = pairs_train[i][1]\n",
    "    X_train[i, 0] = cosine_similarity(A[ids2ind[q1], :], A[ids2ind[q2], :])    \n",
    "    X_train[i, 1] = len(texts[q1].split()) + len(texts[q2].split())\n",
    "    X_train[i, 2] = abs(len(texts[q1].split()) - len(texts[q2].split()))   \n",
    "    X_train[i, 3] = common_words(texts[q1].split(), texts[q2].split())\n",
    "    X_train[i, 4] = diff_words(texts[q1].split(), texts[q2].split())\n",
    "    \n",
    "\n",
    "for i in range(len(pairs_test)):\n",
    "    q1 = pairs_test[i][0]\n",
    "    q2 = pairs_test[i][1]\n",
    "    X_test[i, 0] = cosine_similarity(A[ids2ind[q1], :], A[ids2ind[q2], :])\n",
    "    X_test[i, 1] = len(texts[q1].split()) + len(texts[q2].split())\n",
    "    X_test[i, 2] = abs(len(texts[q1].split()) - len(texts[q2].split()))\n",
    "    X_test[i, 3] = common_words(texts[q1].split(), texts[q2].split())\n",
    "    X_test[i, 4] = diff_words(texts[q1].split(), texts[q2].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross entropy = 4.873214728135228\n"
     ]
    }
   ],
   "source": [
    "loss = log_loss(y_true, y_pred, eps = 1e-15, normalize = True, sample_weight = None, labels = None)\n",
    "print(\"cross entropy = \" + str(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Random Forest', 'Best parameters :', {'n_estimators': 1, 'bootstrap': True, 'criterion': 'entropy', 'max_depth': 20}, 'Loss:', 12.952041148091507)\n",
      "cross entropy = 12.952041148091507\n"
     ]
    }
   ],
   "source": [
    "names_classifier_cv = [\"Random Forest\"]\n",
    "\n",
    "names_classifiers_tunedParams = [\n",
    "    [\"Random Forest\", RandomForestClassifier(), {\"n_estimators\": [1, 5, 10, 50, 100, 500],\n",
    "                                                 \"max_depth\": [1, 3, 5, 10, 20], \n",
    "                                                 \"bootstrap\": [True, False], \n",
    "                                                 \"criterion\": [\"gini\", \"entropy\"]}]\n",
    "]\n",
    "\n",
    "logLoss = []\n",
    "for name, classifer, tunedParam in names_classifiers_tunedParams:\n",
    "    clf = GridSearchCV(classifer, tunedParam)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict_proba(X_test)\n",
    "    loss = log_loss(y_true, y_pred, eps=1e-15, normalize=True, sample_weight=None, labels=None)\n",
    "    print(name, \"Best parameters :\", clf.best_params_, \"Loss:\", loss)\n",
    "    logLoss.append(loss)\n",
    "    \n",
    "    print(\"cross entropy = \" + str(loss))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7AAAAHwCAYAAACfeoOHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEAQsAAAAQxCwAAAADOH/A9bighUMU0CVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x25938a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "x = np.arange(len(logLoss))\n",
    "plt.bar(x, logLoss, alpha=0.5, color=[\"purple\"])\n",
    "plt.xticks(x, names_classifier_cv)\n",
    "plt.xlabel(\"Classifiers\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss for Random forest with Model Tuning\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
